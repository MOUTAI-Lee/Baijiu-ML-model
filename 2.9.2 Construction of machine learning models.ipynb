{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cda4cd8",
   "metadata": {},
   "source": [
    "##  2.9.2 Construction of machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6aa9956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, roc_auc_score, confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize, StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "import os\n",
    "import statsmodels.api as sm  # For LOWESS fitting\n",
    "\n",
    "# Step 1: Read the data\n",
    "file_path = 'C:\\\\Users\\\\Lee66\\\\Desktop\\\\data.csv'\n",
    "try:\n",
    "    data = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "except UnicodeDecodeError:\n",
    "    data = pd.read_csv(file_path, encoding='GBK')\n",
    "\n",
    "# Step 2: Split the data into features and labels\n",
    "X = data.drop(columns=['sample', 'Lable'])  # 'sample' and 'Lable' are dropped\n",
    "y = data['Lable']\n",
    "\n",
    "# Label encoding of target variable\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Step 3: Apply SMOTE for balancing the dataset\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y_encoded)\n",
    "\n",
    "# Step 4: Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_resampled_scaled = scaler.fit_transform(X_resampled)\n",
    "\n",
    "# Step 5: Define machine learning models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=200),\n",
    "    'SVM': SVC(probability=True),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(max_depth=10),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=50, max_depth=10, min_samples_leaf=4),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'MLP': MLPClassifier(max_iter=200, alpha=0.001),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(learning_rate=0.01, max_depth=5),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=50, learning_rate=0.1),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', learning_rate=0.01, max_depth=5)\n",
    "}\n",
    "\n",
    "# Step 6: Initialize result storage\n",
    "results = {}\n",
    "roc_curves = {}\n",
    "\n",
    "# Step 7: Perform cross-validation and store ROC curves\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name} with cross-validation...\")\n",
    "    \n",
    "    # Cross-validation prediction and probability\n",
    "    y_pred = cross_val_predict(model, X_resampled_scaled, y_resampled, cv=cv, method='predict')\n",
    "    y_prob = cross_val_predict(model, X_resampled_scaled, y_resampled, cv=cv, method='predict_proba')\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_resampled, y_pred)\n",
    "    f1 = f1_score(y_resampled, y_pred, average='weighted')\n",
    "    recall = recall_score(y_resampled, y_pred, average='weighted')\n",
    "    precision = precision_score(y_resampled, y_pred, average='weighted')\n",
    "    auc_score = roc_auc_score(label_binarize(y_resampled, classes=np.arange(len(le.classes_))), y_prob, multi_class='ovr', average='weighted')\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1,\n",
    "        'recall': recall,\n",
    "        'precision': precision,\n",
    "        'auc': auc_score,\n",
    "        'confusion_matrix': confusion_matrix(y_resampled, y_pred)\n",
    "    }\n",
    "    \n",
    "    # Compute ROC curves\n",
    "    fpr, tpr, roc_auc = {}, {}, {}\n",
    "    \n",
    "    for i in range(len(le.classes_)):\n",
    "        # ROC curve\n",
    "        fpr[i], tpr[i], _ = roc_curve(label_binarize(y_resampled, classes=np.arange(len(le.classes_)))[:, i], y_prob[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    roc_curves[name] = (fpr, tpr, roc_auc)\n",
    "\n",
    "# Step 8: Output the performance metrics\n",
    "metrics_df = pd.DataFrame(results).T[['accuracy', 'f1_score', 'recall', 'precision', 'auc']]\n",
    "print(metrics_df)\n",
    "\n",
    "# Step 9: Visualize ROC curves\n",
    "for name, (fpr, tpr, roc_auc) in roc_curves.items():\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for i in range(len(le.classes_)):\n",
    "        plt.plot(fpr[i], tpr[i], label=f'Class {le.classes_[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curves for {name}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "# Step 10: Visualize confusion matrices\n",
    "for name, result in results.items():\n",
    "    cm = result['confusion_matrix']\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "    plt.title(f'Confusion Matrix for {name}')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.show()\n",
    "\n",
    "# Step 11: Visualize AUC curves for all models in a single plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'orange', 'purple', 'pink']\n",
    "\n",
    "for idx, (name, (fpr, tpr, roc_auc)) in enumerate(roc_curves.items()):\n",
    "    plt.plot(fpr[0], tpr[0], color=colors[idx], lw=2, label=f'{name} (AUC = {roc_auc[1]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves for All Models')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Step 12: SHAP analysis for the best model \n",
    "best_model = models['XGBoost']  # Use XGBoost for SHAP analysis\n",
    "best_model.fit(X_resampled, y_resampled)  # Train the model\n",
    "\n",
    "# Calculate SHAP values\n",
    "explainer = shap.TreeExplainer(best_model)\n",
    "shap_values = explainer.shap_values(X_resampled)\n",
    "\n",
    "# Step 13: Visualize SHAP summary plot\n",
    "shap.summary_plot(shap_values, X_resampled, feature_names=X.columns)\n",
    "\n",
    "# Step 14: SHAP Beeswarm plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.summary_plot(shap_values, X_resampled, plot_type=\"bee swarm\")\n",
    "\n",
    "# Step 15: SHAP dependence plot with LOWESS\n",
    "feature = 'Compound name'\n",
    "\n",
    "# If shap_values is a list, process it as a numpy array\n",
    "if isinstance(shap_values, list):\n",
    "    shap_values = np.array(shap_values)\n",
    "\n",
    "# Ensure shap_values is 2D for multi-class case\n",
    "if shap_values.ndim > 2:\n",
    "    shap_values_mean = shap_values[0][:, X_resampled.columns.get_loc(feature)]\n",
    "else:\n",
    "    shap_values_mean = shap_values[:, X_resampled.columns.get_loc(feature)]\n",
    "\n",
    "# LOWESS fitting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_resampled[feature], shap_values_mean, color='steelblue', alpha=0.6, label='SHAP values')\n",
    "\n",
    "# Apply LOWESS for smoothing\n",
    "lowess = sm.nonparametric.lowess(shap_values_mean, X_resampled[feature], frac=0.3)\n",
    "x_lowess, y_lowess = zip(*lowess)\n",
    "plt.plot(x_lowess, y_lowess, color='red', linewidth=2, label='LOWESS Curve')\n",
    "\n",
    "# Find intersection points (where SHAP value crosses zero)\n",
    "intersection_indices = np.where(np.diff(np.sign(y_lowess)))[0]\n",
    "for idx in intersection_indices:\n",
    "    plt.axvline(x=x_lowess[idx], color='blue', linestyle='--')\n",
    "\n",
    "plt.xlabel(feature)\n",
    "plt.ylabel('SHAP Value')\n",
    "plt.title(f'SHAP Dependence Plot for {feature}')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "# Save SHAP summary plot and Beeswarm plot as PDFs\n",
    "plt.savefig(os.path.join(os.path.expanduser('~'), 'Desktop', 'SHAP_Summary_Plot)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eli5_env",
   "language": "python",
   "name": "eli5_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
